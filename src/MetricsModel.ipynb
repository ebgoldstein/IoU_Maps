{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.9.1\n",
      " GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#load up the basics\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "#Set GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#import TF stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Check TensorFlow Version\n",
    "print('TF version: {}' .format(tf.__version__))\n",
    "\n",
    "#Check for GPU utilization\n",
    "if tf.test.gpu_device_name():\n",
    "    print(' GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doodled_image</th>\n",
       "      <th>imageP</th>\n",
       "      <th>image</th>\n",
       "      <th>Filename</th>\n",
       "      <th>storm_id</th>\n",
       "      <th>archive</th>\n",
       "      <th>date</th>\n",
       "      <th>ul_lat</th>\n",
       "      <th>ul_lon</th>\n",
       "      <th>...</th>\n",
       "      <th>doodled_only_once</th>\n",
       "      <th>doodled_image_path</th>\n",
       "      <th>doodled_label_path</th>\n",
       "      <th>DiceLoss</th>\n",
       "      <th>mDice</th>\n",
       "      <th>mIoU</th>\n",
       "      <th>IoU_c1</th>\n",
       "      <th>IoU_c2</th>\n",
       "      <th>IoU_c3</th>\n",
       "      <th>IoU_c4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>S21767202-1_Manish Shah.jpg</td>\n",
       "      <td>S21767202-1.jpg</td>\n",
       "      <td>S21767202.jpg</td>\n",
       "      <td>Isaias/20200804a_jpgs/jpgs/S21767202.jpg</td>\n",
       "      <td>isaias</td>\n",
       "      <td>20200804a_jpgs</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>34.775966</td>\n",
       "      <td>-76.410598</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>../data/images/S21767202-1_Manish Shah.jpg</td>\n",
       "      <td>../data/labels/S21767202-1_Manish Shah_label.jpg</td>\n",
       "      <td>0.355374</td>\n",
       "      <td>0.644626</td>\n",
       "      <td>0.565756</td>\n",
       "      <td>0.750846</td>\n",
       "      <td>0.748771</td>\n",
       "      <td>0.761955</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P26157479-0_db.jpg</td>\n",
       "      <td>P26157479-0.jpg</td>\n",
       "      <td>P26157479.jpg</td>\n",
       "      <td>Florence/20180918a_jpgs/jpgs/P26157479.jpg</td>\n",
       "      <td>florence</td>\n",
       "      <td>20180918a_jpgs</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>33.906110</td>\n",
       "      <td>-78.390211</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>../data/images/P26157479-0_db.jpg</td>\n",
       "      <td>../data/labels/P26157479-0_db_label.jpg</td>\n",
       "      <td>0.197519</td>\n",
       "      <td>0.802481</td>\n",
       "      <td>0.687306</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>0.698310</td>\n",
       "      <td>0.561332</td>\n",
       "      <td>0.540384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P26157648-0_db.jpg</td>\n",
       "      <td>P26157648-0.jpg</td>\n",
       "      <td>P26157648.jpg</td>\n",
       "      <td>Florence/20180918a_jpgs/jpgs/P26157648.jpg</td>\n",
       "      <td>florence</td>\n",
       "      <td>20180918a_jpgs</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>33.923909</td>\n",
       "      <td>-78.229009</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>../data/images/P26157648-0_db.jpg</td>\n",
       "      <td>../data/labels/P26157648-0_db_label.jpg</td>\n",
       "      <td>0.386702</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>0.533556</td>\n",
       "      <td>0.878960</td>\n",
       "      <td>0.307724</td>\n",
       "      <td>0.890821</td>\n",
       "      <td>0.056717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P28460585-1_SF.jpg</td>\n",
       "      <td>P28460585-1.jpg</td>\n",
       "      <td>P28460585.jpg</td>\n",
       "      <td>Michael/20181011a_jpgs/jpgs/P28460585.jpg</td>\n",
       "      <td>michael</td>\n",
       "      <td>20181011a_jpgs</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>30.363916</td>\n",
       "      <td>-86.269182</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>../data/images/P28460585-1_SF.jpg</td>\n",
       "      <td>../data/labels/P28460585-1_SF_label.jpg</td>\n",
       "      <td>0.130847</td>\n",
       "      <td>0.869153</td>\n",
       "      <td>0.771531</td>\n",
       "      <td>0.826177</td>\n",
       "      <td>0.715110</td>\n",
       "      <td>0.832978</td>\n",
       "      <td>0.711861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P26157388-0_JJF.jpg</td>\n",
       "      <td>P26157388-0.jpg</td>\n",
       "      <td>P26157388.jpg</td>\n",
       "      <td>Florence/20180918a_jpgs/jpgs/P26157388.jpg</td>\n",
       "      <td>florence</td>\n",
       "      <td>20180918a_jpgs</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>33.878152</td>\n",
       "      <td>-78.493664</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>../data/images/P26157388-0_JJF.jpg</td>\n",
       "      <td>../data/labels/P26157388-0_JJF_label.jpg</td>\n",
       "      <td>0.177504</td>\n",
       "      <td>0.822496</td>\n",
       "      <td>0.715360</td>\n",
       "      <td>0.722921</td>\n",
       "      <td>0.748157</td>\n",
       "      <td>0.898927</td>\n",
       "      <td>0.491436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                doodled_image           imageP          image  \\\n",
       "0           0  S21767202-1_Manish Shah.jpg  S21767202-1.jpg  S21767202.jpg   \n",
       "1           1           P26157479-0_db.jpg  P26157479-0.jpg  P26157479.jpg   \n",
       "2           2           P26157648-0_db.jpg  P26157648-0.jpg  P26157648.jpg   \n",
       "3           3           P28460585-1_SF.jpg  P28460585-1.jpg  P28460585.jpg   \n",
       "4           4          P26157388-0_JJF.jpg  P26157388-0.jpg  P26157388.jpg   \n",
       "\n",
       "                                     Filename  storm_id         archive  \\\n",
       "0    Isaias/20200804a_jpgs/jpgs/S21767202.jpg    isaias  20200804a_jpgs   \n",
       "1  Florence/20180918a_jpgs/jpgs/P26157479.jpg  florence  20180918a_jpgs   \n",
       "2  Florence/20180918a_jpgs/jpgs/P26157648.jpg  florence  20180918a_jpgs   \n",
       "3   Michael/20181011a_jpgs/jpgs/P28460585.jpg   michael  20181011a_jpgs   \n",
       "4  Florence/20180918a_jpgs/jpgs/P26157388.jpg  florence  20180918a_jpgs   \n",
       "\n",
       "         date     ul_lat     ul_lon  ...  doodled_only_once  \\\n",
       "0  2020-08-04  34.775966 -76.410598  ...               True   \n",
       "1  2018-09-18  33.906110 -78.390211  ...               True   \n",
       "2  2018-09-18  33.923909 -78.229009  ...               True   \n",
       "3  2018-10-11  30.363916 -86.269182  ...               True   \n",
       "4  2018-09-18  33.878152 -78.493664  ...               True   \n",
       "\n",
       "                           doodled_image_path  \\\n",
       "0  ../data/images/S21767202-1_Manish Shah.jpg   \n",
       "1           ../data/images/P26157479-0_db.jpg   \n",
       "2           ../data/images/P26157648-0_db.jpg   \n",
       "3           ../data/images/P28460585-1_SF.jpg   \n",
       "4          ../data/images/P26157388-0_JJF.jpg   \n",
       "\n",
       "                                 doodled_label_path  DiceLoss     mDice  \\\n",
       "0  ../data/labels/S21767202-1_Manish Shah_label.jpg  0.355374  0.644626   \n",
       "1           ../data/labels/P26157479-0_db_label.jpg  0.197519  0.802481   \n",
       "2           ../data/labels/P26157648-0_db_label.jpg  0.386702  0.613298   \n",
       "3           ../data/labels/P28460585-1_SF_label.jpg  0.130847  0.869153   \n",
       "4          ../data/labels/P26157388-0_JJF_label.jpg  0.177504  0.822496   \n",
       "\n",
       "       mIoU    IoU_c1    IoU_c2    IoU_c3    IoU_c4  \n",
       "0  0.565756  0.750846  0.748771  0.761955  0.001452  \n",
       "1  0.687306  0.949200  0.698310  0.561332  0.540384  \n",
       "2  0.533556  0.878960  0.307724  0.890821  0.056717  \n",
       "3  0.771531  0.826177  0.715110  0.832978  0.711861  \n",
       "4  0.715360  0.722921  0.748157  0.898927  0.491436  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load in DF\n",
    "doodlecsvpath = '../data/Preds.csv'\n",
    "doodlecsv = pd.read_csv(doodlecsvpath)\n",
    "doodlecsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_columns = [\"mDice\", \"mIoU\", \"IoU_c1\",\n",
    "\"IoU_c2\",\"IoU_c3\", \"IoU_c4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load up the TF model\n",
    "\n",
    "#model path\n",
    "model_path = '../model/NOAA_NewLoss_fullmodel_model'\n",
    "\n",
    "# load model into tf\n",
    "model_base = tf.keras.models.load_model(model_path, compile = True)\n",
    "\n",
    "\n",
    "model_base.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization using adjusted standard deviation, as required by Gym model\n",
    "\n",
    "def standardize(img):\n",
    "\n",
    "    N = np.shape(img)[0] * np.shape(img)[1]\n",
    "    s = np.maximum(np.std(img), 1.0 / np.sqrt(N))\n",
    "    m = np.mean(img)\n",
    "    img = (img - m) / s\n",
    "    del m, s, N\n",
    "    #\n",
    "    if np.ndim(img) == 2:\n",
    "        img = np.dstack((img, img, img))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 768, 1024,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 768, 1024, 4  52          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 768, 1024, 4  16         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 768, 1024, 4  16          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 768, 1024, 4  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 768, 1024, 4  16         ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 768, 1024, 4  68          ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 768, 1024, 4  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 768, 1024, 4  0           ['conv2d_1[0][0]',               \n",
      "                                )                                 'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768, 1024, 4  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 768, 1024, 4  16         ['dropout[0][0]']                \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 768, 1024, 4  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 384, 512, 8)  2600        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 384, 512, 8)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 384, 512, 8)  40          ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 384, 512, 8)  32         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 384, 512, 8)  32         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 384, 512, 8)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 384, 512, 8)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 384, 512, 8)  5192        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 384, 512, 8)  0           ['activation_4[0][0]',           \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 384, 512, 8)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 384, 512, 8)  32         ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 384, 512, 8)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 192, 256, 16  10384       ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 192, 256, 16  0           ['conv2d_6[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 192, 256, 16  144         ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 192, 256, 16  64         ['dropout_3[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 192, 256, 16  64         ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 192, 256, 16  0           ['batch_normalization_6[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 192, 256, 16  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 192, 256, 16  20752       ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 192, 256, 16  0           ['activation_7[0][0]',           \n",
      "                                )                                 'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 192, 256, 16  0           ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 192, 256, 16  64         ['dropout_4[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 192, 256, 16  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 96, 128, 32)  41504       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 96, 128, 32)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 96, 128, 32)  544         ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 96, 128, 32)  128        ['dropout_5[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 96, 128, 32)  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 96, 128, 32)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 96, 128, 32)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 96, 128, 32)  82976       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 96, 128, 32)  0           ['activation_10[0][0]',          \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 96, 128, 32)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 96, 128, 32)  128        ['dropout_6[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 96, 128, 32)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 48, 64, 64)   165952      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 48, 64, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 48, 64, 64)   2112        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 48, 64, 64)  256         ['dropout_7[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 48, 64, 64)  256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 48, 64, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 48, 64, 64)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 48, 64, 64)   331840      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 48, 64, 64)   0           ['activation_13[0][0]',          \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 48, 64, 64)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 48, 64, 64)  256         ['dropout_8[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 48, 64, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 48, 64, 64)   331840      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 48, 64, 64)   0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 48, 64, 64)  256         ['dropout_9[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_15 (Activation)     (None, 48, 64, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 48, 64, 64)   331840      ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 96, 128, 64)  0           ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 96, 128, 96)  0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 96, 128, 96)  384        ['concatenate[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 96, 128, 96)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 96, 128, 64)  497728      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 96, 128, 64)  6208        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 96, 128, 64)  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 96, 128, 64)  256        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 96, 128, 64)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 96, 128, 64)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 96, 128, 64)  331840      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 96, 128, 64)  0           ['activation_18[0][0]',          \n",
      "                                                                  'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 192, 256, 64  0          ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 192, 256, 80  0           ['up_sampling2d_1[0][0]',        \n",
      "                                )                                 'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 192, 256, 80  320        ['concatenate_1[0][0]']          \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 192, 256, 80  0           ['batch_normalization_19[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 192, 256, 32  207392      ['activation_19[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 192, 256, 32  2592        ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 192, 256, 32  128        ['conv2d_20[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 192, 256, 32  128        ['conv2d_22[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 192, 256, 32  0           ['batch_normalization_20[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 192, 256, 32  0           ['batch_normalization_21[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 192, 256, 32  82976       ['activation_20[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 192, 256, 32  0           ['activation_21[0][0]',          \n",
      "                                )                                 'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 384, 512, 32  0          ['add_6[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 384, 512, 40  0           ['up_sampling2d_2[0][0]',        \n",
      "                                )                                 'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 384, 512, 40  160        ['concatenate_2[0][0]']          \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 384, 512, 40  0           ['batch_normalization_22[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 384, 512, 16  51856       ['activation_22[0][0]']          \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 384, 512, 16  656         ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 384, 512, 16  64         ['conv2d_23[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 384, 512, 16  64         ['conv2d_25[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 384, 512, 16  0           ['batch_normalization_23[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 384, 512, 16  0           ['batch_normalization_24[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 384, 512, 16  20752       ['activation_23[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 384, 512, 16  0           ['activation_24[0][0]',          \n",
      "                                )                                 'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 768, 1024, 1  0          ['add_7[0][0]']                  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 768, 1024, 2  0           ['up_sampling2d_3[0][0]',        \n",
      "                                0)                                'add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 768, 1024, 2  80         ['concatenate_3[0][0]']          \n",
      " ormalization)                  0)                                                                \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 768, 1024, 2  0           ['batch_normalization_25[0][0]'] \n",
      "                                0)                                                                \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 768, 1024, 8  12968       ['activation_25[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 768, 1024, 8  168         ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 768, 1024, 8  32         ['conv2d_26[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 768, 1024, 8  32         ['conv2d_28[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 768, 1024, 8  0           ['batch_normalization_26[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 768, 1024, 8  0           ['batch_normalization_27[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 768, 1024, 8  5192        ['activation_26[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 768, 1024, 8  0           ['activation_27[0][0]',          \n",
      "                                )                                 'conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 768, 1024, 4  36          ['add_8[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,551,868\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,551,868\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 768, 1024,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 768, 1024, 4  52          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 768, 1024, 4  16         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 768, 1024, 4  16          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 768, 1024, 4  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 768, 1024, 4  16         ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 768, 1024, 4  68          ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 768, 1024, 4  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 768, 1024, 4  0           ['conv2d_1[0][0]',               \n",
      "                                )                                 'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768, 1024, 4  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 768, 1024, 4  16         ['dropout[0][0]']                \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 768, 1024, 4  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 384, 512, 8)  2600        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 384, 512, 8)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 384, 512, 8)  40          ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 384, 512, 8)  32         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 384, 512, 8)  32         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 384, 512, 8)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 384, 512, 8)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 384, 512, 8)  5192        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 384, 512, 8)  0           ['activation_4[0][0]',           \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 384, 512, 8)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 384, 512, 8)  32         ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 384, 512, 8)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 192, 256, 16  10384       ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 192, 256, 16  0           ['conv2d_6[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 192, 256, 16  144         ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 192, 256, 16  64         ['dropout_3[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 192, 256, 16  64         ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 192, 256, 16  0           ['batch_normalization_6[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 192, 256, 16  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 192, 256, 16  20752       ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 192, 256, 16  0           ['activation_7[0][0]',           \n",
      "                                )                                 'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 192, 256, 16  0           ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 192, 256, 16  64         ['dropout_4[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 192, 256, 16  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 96, 128, 32)  41504       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 96, 128, 32)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 96, 128, 32)  544         ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 96, 128, 32)  128        ['dropout_5[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 96, 128, 32)  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 96, 128, 32)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 96, 128, 32)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 96, 128, 32)  82976       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 96, 128, 32)  0           ['activation_10[0][0]',          \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 96, 128, 32)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 96, 128, 32)  128        ['dropout_6[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 96, 128, 32)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 48, 64, 64)   165952      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 48, 64, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 48, 64, 64)  256         ['dropout_7[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 48, 64, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 64)          0           ['activation_12[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          33280       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " drd1 (Dropout)                 (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          262656      ['drd1[0][0]']                   \n",
      "                                                                                                  \n",
      " drd2 (Dropout)                 (None, 512)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            3078        ['drd2[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 630,214\n",
      "Trainable params: 299,014\n",
      "Non-trainable params: 331,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = model_base.get_layer('activation_12').output\n",
    "\n",
    "# add avg pool\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# Add a dense Layer\n",
    "x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(1e-4))(x)\n",
    "# Add a dropout rate of 0.5\n",
    "x = tf.keras.layers.Dropout(0.5, name='drd1')(x)\n",
    "# Add a dense Layer\n",
    "x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(1e-4))(x)\n",
    "# Add a dropout rate of 0.5\n",
    "x = tf.keras.layers.Dropout(0.5, name='drd2')(x)\n",
    "# Add a final linear layer for classification\n",
    "x = tf.keras.layers.Dense(len(p_columns), activation='relu')(x) \n",
    "\n",
    "\n",
    "model = tf.keras.Model(model_base.input, x) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 840 validated image filenames.\n",
      "Found 210 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#build data generators for training and validaton\n",
    "\n",
    "#split is 70/20/10 for 300 images, so XX 210 image, 60 images, 30 images.. \n",
    "#the 30 have been removed for testing already, so its 22.23% of teh remaining images as validation\n",
    "split = 0.2\n",
    "\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator and split data\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'reflect',\n",
    "    preprocessing_function = standardize,\n",
    "    validation_split = split)\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function = standardize, validation_split = split)\n",
    "\n",
    "\n",
    "#set batch Size\n",
    "batch_size = 8\n",
    "\n",
    "#set color\n",
    "# c_ch = 1\n",
    "# c_mode = 'grayscale'\n",
    "c_ch = 3\n",
    "\n",
    "#set Image size (RGB so imshape is 3)\n",
    "imsize = (768, 1024) \n",
    "imshape = (768, 1024, 3)\n",
    "\n",
    "# Flow training images in batches \n",
    "train_generator = datagen.flow_from_dataframe(dataframe = doodlecsv,\n",
    "                                                    directory = \"\",\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'raw',\n",
    "                                                    x_col = 'doodled_image_path',\n",
    "                                                    y_col = p_columns,\n",
    "                                                    target_size = imsize,\n",
    "                                                    color_mode = 'rgb',\n",
    "                                                    seed = 11,\n",
    "                                                    shuffle=False,\n",
    "                                                    subset ='training')\n",
    "\n",
    "# Flow validation images in batches \n",
    "validation_generator =  val_datagen.flow_from_dataframe(dataframe=doodlecsv,\n",
    "                                                          directory = \"\",\n",
    "                                                          batch_size = batch_size,\n",
    "                                                          class_mode = 'raw',\n",
    "                                                          x_col = 'doodled_image_path',\n",
    "                                                          y_col = p_columns,\n",
    "                                                          target_size = imsize,\n",
    "                                                          color_mode = 'rgb',\n",
    "                                                          seed = 11,\n",
    "                                                          shuffle=False,\n",
    "                                                          subset ='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define other metrics\n",
    "MAE = tf.keras.metrics.MeanAbsoluteError(name='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss = tf.keras.losses.MeanSquaredError(), \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-4), \n",
    "              metrics = [MAE]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a callback\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             patience = 40, \n",
    "                                             restore_best_weights = True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                 factor = 0.2,\n",
    "                                                 verbose = 1,\n",
    "                                                 patience = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "105/105 [==============================] - 13s 92ms/step - loss: 0.2094 - mae: 0.3103 - val_loss: 0.1208 - val_mae: 0.2077 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.1486 - mae: 0.2460 - val_loss: 0.1074 - val_mae: 0.1844 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.1323 - mae: 0.2271 - val_loss: 0.1022 - val_mae: 0.1818 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.1224 - mae: 0.2140 - val_loss: 0.0985 - val_mae: 0.1724 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.1157 - mae: 0.2054 - val_loss: 0.0959 - val_mae: 0.1747 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.1105 - mae: 0.2005 - val_loss: 0.0957 - val_mae: 0.1717 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "105/105 [==============================] - 9s 85ms/step - loss: 0.1084 - mae: 0.1988 - val_loss: 0.0912 - val_mae: 0.1656 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.1029 - mae: 0.1908 - val_loss: 0.0914 - val_mae: 0.1649 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.1022 - mae: 0.1910 - val_loss: 0.0891 - val_mae: 0.1634 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0995 - mae: 0.1870 - val_loss: 0.0880 - val_mae: 0.1603 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.0966 - mae: 0.1819 - val_loss: 0.0880 - val_mae: 0.1618 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0950 - mae: 0.1811 - val_loss: 0.0865 - val_mae: 0.1592 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "105/105 [==============================] - 9s 86ms/step - loss: 0.0938 - mae: 0.1790 - val_loss: 0.0866 - val_mae: 0.1605 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0907 - mae: 0.1743 - val_loss: 0.0850 - val_mae: 0.1564 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0900 - mae: 0.1734 - val_loss: 0.0839 - val_mae: 0.1565 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0901 - mae: 0.1744 - val_loss: 0.0819 - val_mae: 0.1530 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0896 - mae: 0.1739 - val_loss: 0.0818 - val_mae: 0.1574 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0874 - mae: 0.1709 - val_loss: 0.0803 - val_mae: 0.1528 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0858 - mae: 0.1698 - val_loss: 0.0799 - val_mae: 0.1530 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0843 - mae: 0.1665 - val_loss: 0.0796 - val_mae: 0.1519 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0833 - mae: 0.1666 - val_loss: 0.0797 - val_mae: 0.1511 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0828 - mae: 0.1645 - val_loss: 0.0784 - val_mae: 0.1502 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0819 - mae: 0.1655 - val_loss: 0.0777 - val_mae: 0.1543 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0813 - mae: 0.1650 - val_loss: 0.0767 - val_mae: 0.1500 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0790 - mae: 0.1606 - val_loss: 0.0770 - val_mae: 0.1494 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0786 - mae: 0.1616 - val_loss: 0.0767 - val_mae: 0.1502 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0782 - mae: 0.1605 - val_loss: 0.0758 - val_mae: 0.1472 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0771 - mae: 0.1591 - val_loss: 0.0741 - val_mae: 0.1491 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0771 - mae: 0.1590 - val_loss: 0.0749 - val_mae: 0.1487 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "105/105 [==============================] - 10s 88ms/step - loss: 0.0757 - mae: 0.1575 - val_loss: 0.0747 - val_mae: 0.1490 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0756 - mae: 0.1586 - val_loss: 0.0765 - val_mae: 0.1518 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0728 - mae: 0.1524 - val_loss: 0.0743 - val_mae: 0.1485 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0736 - mae: 0.1559 - val_loss: 0.0719 - val_mae: 0.1456 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0721 - mae: 0.1534 - val_loss: 0.0717 - val_mae: 0.1456 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0715 - mae: 0.1532 - val_loss: 0.0710 - val_mae: 0.1486 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0711 - mae: 0.1531 - val_loss: 0.0704 - val_mae: 0.1442 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0708 - mae: 0.1541 - val_loss: 0.0701 - val_mae: 0.1457 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0697 - mae: 0.1515 - val_loss: 0.0717 - val_mae: 0.1487 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0696 - mae: 0.1529 - val_loss: 0.0720 - val_mae: 0.1503 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0669 - mae: 0.1473 - val_loss: 0.0722 - val_mae: 0.1504 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0660 - mae: 0.1449 - val_loss: 0.0702 - val_mae: 0.1472 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0668 - mae: 0.1482 - val_loss: 0.0698 - val_mae: 0.1476 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0659 - mae: 0.1472 - val_loss: 0.0722 - val_mae: 0.1531 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0650 - mae: 0.1456 - val_loss: 0.0661 - val_mae: 0.1413 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0653 - mae: 0.1480 - val_loss: 0.0668 - val_mae: 0.1430 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0644 - mae: 0.1466 - val_loss: 0.0682 - val_mae: 0.1456 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0649 - mae: 0.1477 - val_loss: 0.0714 - val_mae: 0.1547 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0628 - mae: 0.1445 - val_loss: 0.0661 - val_mae: 0.1430 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0633 - mae: 0.1455 - val_loss: 0.0659 - val_mae: 0.1432 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0616 - mae: 0.1428 - val_loss: 0.0671 - val_mae: 0.1468 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0609 - mae: 0.1411 - val_loss: 0.0679 - val_mae: 0.1484 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0611 - mae: 0.1428 - val_loss: 0.0660 - val_mae: 0.1465 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0606 - mae: 0.1420 - val_loss: 0.0648 - val_mae: 0.1430 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0593 - mae: 0.1399 - val_loss: 0.0616 - val_mae: 0.1387 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0591 - mae: 0.1406 - val_loss: 0.0645 - val_mae: 0.1437 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0595 - mae: 0.1413 - val_loss: 0.0644 - val_mae: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0574 - mae: 0.1383 - val_loss: 0.0627 - val_mae: 0.1423 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0587 - mae: 0.1411 - val_loss: 0.0651 - val_mae: 0.1473 - lr: 1.0000e-04\n",
      "Epoch 59/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0577 - mae: 0.1400 - val_loss: 0.0607 - val_mae: 0.1385 - lr: 1.0000e-04\n",
      "Epoch 60/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0566 - mae: 0.1377 - val_loss: 0.0611 - val_mae: 0.1403 - lr: 1.0000e-04\n",
      "Epoch 61/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0559 - mae: 0.1360 - val_loss: 0.0612 - val_mae: 0.1396 - lr: 1.0000e-04\n",
      "Epoch 62/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0566 - mae: 0.1384 - val_loss: 0.0610 - val_mae: 0.1404 - lr: 1.0000e-04\n",
      "Epoch 63/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0550 - mae: 0.1357 - val_loss: 0.0605 - val_mae: 0.1398 - lr: 1.0000e-04\n",
      "Epoch 64/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0556 - mae: 0.1372 - val_loss: 0.0590 - val_mae: 0.1376 - lr: 1.0000e-04\n",
      "Epoch 65/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0542 - mae: 0.1349 - val_loss: 0.0582 - val_mae: 0.1366 - lr: 1.0000e-04\n",
      "Epoch 66/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0538 - mae: 0.1351 - val_loss: 0.0598 - val_mae: 0.1402 - lr: 1.0000e-04\n",
      "Epoch 67/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0524 - mae: 0.1319 - val_loss: 0.0591 - val_mae: 0.1380 - lr: 1.0000e-04\n",
      "Epoch 68/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0528 - mae: 0.1333 - val_loss: 0.0625 - val_mae: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 69/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0525 - mae: 0.1320 - val_loss: 0.0572 - val_mae: 0.1356 - lr: 1.0000e-04\n",
      "Epoch 70/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0523 - mae: 0.1331 - val_loss: 0.0600 - val_mae: 0.1417 - lr: 1.0000e-04\n",
      "Epoch 71/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0509 - mae: 0.1300 - val_loss: 0.0592 - val_mae: 0.1404 - lr: 1.0000e-04\n",
      "Epoch 72/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0522 - mae: 0.1337 - val_loss: 0.0565 - val_mae: 0.1356 - lr: 1.0000e-04\n",
      "Epoch 73/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0519 - mae: 0.1331 - val_loss: 0.0571 - val_mae: 0.1383 - lr: 1.0000e-04\n",
      "Epoch 74/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0510 - mae: 0.1319 - val_loss: 0.0568 - val_mae: 0.1380 - lr: 1.0000e-04\n",
      "Epoch 75/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0498 - mae: 0.1298 - val_loss: 0.0580 - val_mae: 0.1398 - lr: 1.0000e-04\n",
      "Epoch 76/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0499 - mae: 0.1303 - val_loss: 0.0598 - val_mae: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 77/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0490 - mae: 0.1283\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0490 - mae: 0.1283 - val_loss: 0.0627 - val_mae: 0.1521 - lr: 1.0000e-04\n",
      "Epoch 78/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0491 - mae: 0.1283 - val_loss: 0.0571 - val_mae: 0.1390 - lr: 2.0000e-05\n",
      "Epoch 79/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0485 - mae: 0.1275 - val_loss: 0.0560 - val_mae: 0.1363 - lr: 2.0000e-05\n",
      "Epoch 80/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0478 - mae: 0.1260 - val_loss: 0.0558 - val_mae: 0.1363 - lr: 2.0000e-05\n",
      "Epoch 81/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0485 - mae: 0.1270 - val_loss: 0.0559 - val_mae: 0.1370 - lr: 2.0000e-05\n",
      "Epoch 82/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0482 - mae: 0.1265 - val_loss: 0.0569 - val_mae: 0.1391 - lr: 2.0000e-05\n",
      "Epoch 83/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0474 - mae: 0.1263 - val_loss: 0.0569 - val_mae: 0.1388 - lr: 2.0000e-05\n",
      "Epoch 84/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0472 - mae: 0.1243 - val_loss: 0.0560 - val_mae: 0.1372 - lr: 2.0000e-05\n",
      "Epoch 85/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0471 - mae: 0.1257\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0471 - mae: 0.1257 - val_loss: 0.0563 - val_mae: 0.1380 - lr: 2.0000e-05\n",
      "Epoch 86/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0470 - mae: 0.1246 - val_loss: 0.0561 - val_mae: 0.1376 - lr: 4.0000e-06\n",
      "Epoch 87/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0477 - mae: 0.1269 - val_loss: 0.0561 - val_mae: 0.1377 - lr: 4.0000e-06\n",
      "Epoch 88/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0473 - mae: 0.1252 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 4.0000e-06\n",
      "Epoch 89/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0470 - mae: 0.1245 - val_loss: 0.0558 - val_mae: 0.1369 - lr: 4.0000e-06\n",
      "Epoch 90/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0476 - mae: 0.1269\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0476 - mae: 0.1269 - val_loss: 0.0559 - val_mae: 0.1372 - lr: 4.0000e-06\n",
      "Epoch 91/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0474 - mae: 0.1256 - val_loss: 0.0560 - val_mae: 0.1373 - lr: 8.0000e-07\n",
      "Epoch 92/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0467 - mae: 0.1241 - val_loss: 0.0560 - val_mae: 0.1373 - lr: 8.0000e-07\n",
      "Epoch 93/200\n",
      "105/105 [==============================] - 10s 90ms/step - loss: 0.0475 - mae: 0.1257 - val_loss: 0.0560 - val_mae: 0.1373 - lr: 8.0000e-07\n",
      "Epoch 94/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0466 - mae: 0.1240 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 8.0000e-07\n",
      "Epoch 95/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0475 - mae: 0.1265\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0475 - mae: 0.1265 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 8.0000e-07\n",
      "Epoch 96/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0475 - mae: 0.1264 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 1.6000e-07\n",
      "Epoch 97/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0474 - mae: 0.1261 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 1.6000e-07\n",
      "Epoch 98/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0476 - mae: 0.1265 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 1.6000e-07\n",
      "Epoch 99/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0465 - mae: 0.1236 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 1.6000e-07\n",
      "Epoch 100/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0470 - mae: 0.1254\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0470 - mae: 0.1254 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 1.6000e-07\n",
      "Epoch 101/200\n",
      "105/105 [==============================] - 10s 89ms/step - loss: 0.0471 - mae: 0.1254 - val_loss: 0.0560 - val_mae: 0.1374 - lr: 3.2000e-08\n",
      "Epoch 102/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0469 - mae: 0.1249 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 3.2000e-08\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0479 - mae: 0.1270 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 3.2000e-08\n",
      "Epoch 104/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0470 - mae: 0.1243 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 3.2000e-08\n",
      "Epoch 105/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0472 - mae: 0.1255\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0472 - mae: 0.1255 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 3.2000e-08\n",
      "Epoch 106/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0469 - mae: 0.1247 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 6.4000e-09\n",
      "Epoch 107/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0465 - mae: 0.1246 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 6.4000e-09\n",
      "Epoch 108/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0470 - mae: 0.1245 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 6.4000e-09\n",
      "Epoch 109/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0470 - mae: 0.1245 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 6.4000e-09\n",
      "Epoch 110/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0469 - mae: 0.1260\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0469 - mae: 0.1260 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 6.4000e-09\n",
      "Epoch 111/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0469 - mae: 0.1246 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.2800e-09\n",
      "Epoch 112/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0460 - mae: 0.1223 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.2800e-09\n",
      "Epoch 113/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0475 - mae: 0.1258 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.2800e-09\n",
      "Epoch 114/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0465 - mae: 0.1235 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.2800e-09\n",
      "Epoch 115/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0467 - mae: 0.1236\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0467 - mae: 0.1236 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.2800e-09\n",
      "Epoch 116/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0474 - mae: 0.1262 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 2.5600e-10\n",
      "Epoch 117/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0467 - mae: 0.1246 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 2.5600e-10\n",
      "Epoch 118/200\n",
      "105/105 [==============================] - 9s 89ms/step - loss: 0.0470 - mae: 0.1235 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 2.5600e-10\n",
      "Epoch 119/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0464 - mae: 0.1234 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 2.5600e-10\n",
      "Epoch 120/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0465 - mae: 0.1224\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0465 - mae: 0.1224 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 2.5600e-10\n",
      "Epoch 121/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0474 - mae: 0.1262 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 5.1200e-11\n",
      "Epoch 122/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0473 - mae: 0.1255 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 5.1200e-11\n",
      "Epoch 123/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0461 - mae: 0.1230 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 5.1200e-11\n",
      "Epoch 124/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0467 - mae: 0.1242 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 5.1200e-11\n",
      "Epoch 125/200\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0476 - mae: 0.1266\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 1.0239999126415712e-11.\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0476 - mae: 0.1266 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 5.1200e-11\n",
      "Epoch 126/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0471 - mae: 0.1247 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.0240e-11\n",
      "Epoch 127/200\n",
      "105/105 [==============================] - 9s 87ms/step - loss: 0.0466 - mae: 0.1243 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.0240e-11\n",
      "Epoch 128/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0467 - mae: 0.1242 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.0240e-11\n",
      "Epoch 129/200\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0474 - mae: 0.1269 - val_loss: 0.0560 - val_mae: 0.1375 - lr: 1.0240e-11\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    epochs= 200,\n",
    "                    workers = 8,\n",
    "                    callbacks =[early_stop, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at the metrics from training\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.ylim(0,70)\n",
    "\n",
    "plt.title('Training and validation loss (MSE})')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "plt.plot(epochs, mae, 'r', label='Training')\n",
    "plt.plot(epochs, val_mae, 'b', label='Validation')\n",
    "#plt.ylim(0,1)\n",
    "\n",
    "plt.title('Training and validation MAE')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/PredictIoU/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/PredictIoU/assets\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "filepath = './model/PredictIoU'\n",
    "model.save(filepath)\n",
    "\n",
    "#load model\n",
    "#model = tf.keras.models.load_model(filepath, compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
